# [ 인공지능의 발전 ]

## 1. 인공지능의 과거

1. 계산기 : 단순한 수치적 연산, 파스칼 발명

1. 컴퓨터 : 앨런 튜링의 ‘생각하는 기계’ 개념 제시 & 논리적 행위의 구현
    - 인공지능 = 인간이 하는 논리적 행위(인지, 판단 등)를 모방하는 기계

1. 인공지능의 암흑기
    - (1950) 인공신경망 개념 제시 (인간의 두뇌를 모방하여 만든 수학적 모델)
    - (1960) 퍼셉트론 등장 (가장 단순한 인공신경망)
    - (1970) 대규모 신경망의 불안정성 문제 - 계산 능력 부재
    - (1980) 학습 알고리즘의 문제 - 과최적화 문제

- 과거의 인공지능 : 단순한 규칙기반 혹은 탐색 기반의 인공지능이 선호 (복잡한 지능 묘사 불가능)
    - 인공지능의 접근
        1. 규칙 기반
            - 명확한 규칙이 존재하고 그 규칙에 따라서 판단
            - 다양한 소스로부터 규칙을 수집하고 정리하는 것이 주된 요구사항
            - ex. 대출 신청, 장학금 결정
            - 법률과 같이 복합적인 규칙이 있는 분야에서 한계를 보임
        2. 데이터 기반
            - 대략적인 규칙은 존재하지만 명확하지는 않음
            - 많은 사례로부터 대략적인 규칙을 배우는 것이 주된 요구사항
            - 머신러닝, 기계학습
        
        → 하나의 인공지능 서비스를 만들기 위해서는 모든 접근법이 적절히 융합되어 사용
        

## 2. 정보화 시대 (1990년대)

1. 컴퓨터의 발전
    - `무어의 법칙` : 컴퓨터에 들어가는 트랜지스터가 매년 2배씩 증가
    - 계산 및 처리 속도 급격히 증가 → 데이터 저장 용량의 증가, 가격 하락
2. 인터넷의 발전
    - 전산적으로 처리가 가능한 데이터의 증가 → 데이터의 수집과 공유가 가능
3. 데이터 처리 기법의 발전
    - 대용량 데이터 저장, 관리, 분석 기법의 개발 & 새로운 데이터 예측 기법의 발견

- `빅데이터`
    - 복잡한 대규모 데이터에 새로운 분석 방법론과 관리도구를 적용하여 새로운 정보를 찾을 수 있음
    - `3V` : `Volume` (데이터 크기), `Variety` (데이터 형태), `Velocity` (데이터 생성, 유통, 분석, 소비)
    - 대규모 데이터의 효과적인 수집, 관리, 분석이 중요

- (1990대 후반) 제프리 힌턴의 딥 빌리프 네트워크 발표 이후 인공지능 붐

- 딥러닝 모델
    - 외부로 나타나지 않고 숨겨진 계층(hidden layer)가 다수 존재하는 신경망 모델
    - 숨겨진 변수가 학습을 통해 필요한 정보(feature)를 추출하는 모델
        
        → 모델이 자동으로 유용한 정보를 추출하여 사용
        
        ![2024-10-22_03-51-38.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/60abfa04-4926-4cf2-a7d1-fa502796028f/2024-10-22_03-51-38.jpg)
        

- 인공지능의 봄-여름 (2000년대 중반)

## 3. 인공지능의 발전 방향

1. 일반적인 인공지능 (AGI, general)
    - 하나의 문제에 특화보다, 인간과 같이 한 프로그램이 다양한 문제를 해결
    - `멀티모달 학습`이 필요
        - 다양한 종류의 데이터를 학습하여 다양한 문제를 해결
        - ex. Image captioning, Video Q&A, ChatGPT

1. 인공초지능 (ASI, super)
    - 인간보다 우수한 판단력을 지녀 새로운 해결법을 발견
    - `강화 학습`이 필요
        - 기본적인 규칙을 기반으로 스스로 학습하는 과정을 통해 **알파고**와 같은 성과

---

# [ 기계학습 개요 ]

## 1. 학습

- 인공지능의 수학적 표현
    - 입력 x(Environment)와 출력 y(Action) 사이의 관계를 정의하는 함수 f
    - 어떠한 분포로부터 임의로 주어지는 데이터를 통해 확률적 예측을 바탕으로 결정

- 학습
    - 임의의 관측 데이터 : 모집단으로부터 임의로 추출된 데이터, 무작위로 샘플링된 관측값
    - 목표 = 관측된 데이터로부터 모집단의 일반적인 특성을 추정 (오류를 최소화)
    - 일반적으로 수집된 데이터를 과거에 나누어 훈련 세트(training set)와 테스트 세트(test set)로 분리하고, 이를 통해 모델을 학습
        - 모든 과정은 동일한 확률적 과정으로 이루어지며, 단지 데이터가 과거에 수집되었는지 미래에 수집되었는지의 차이일 뿐

## 2. 모델의 복잡성

- `모델 복잡성`
    - 어떤 모델이 표현한 수 있는 데이터 패턴의 범위
    - 수치적으로 잘 정의되지는 않지만 모델들끼리의 비교를 통해 상대적으로 확인 가능
    - 유연성(flexibility), 자유도(degree of freedom) 등으로 불리기도 함
    - ex. 𝑓(𝑥) = 𝑎𝑥2 + 𝑏𝑥 + 𝑐 vs. 𝑓(𝑥) = 𝑎𝑥 + 𝑏
    
- 복잡성에 따른 모델의 성능
    - 모델이 복잡할 수록 훈련 데이터에서의 성능은 향상
    - 일반적인 성능(평가 데이터에서의 성능)은 그렇지 않음
    1. `Underfitting` : 모델이 너무 단순해서 훈련/평가데이터 둘 다 못 맞추는 현상
    2. `Overfitting` : 모델이 너무 복잡해서 훈련데이터는 잘 맞추지만 평가데이터는 못 맞추는 현상
        
        ⇒ 적절힌 복잡성 탐색 필요
        

## 3. 기계학습

- 분류
    1. `지도 학습`
        - 데이터의 X와 Y가 주어졌을 때, `Y를 예측`하기 위한 함수를 찾는 문제
        - 입력과 출력이 모두 주어진 데이터로 모델을 학습시키는 방식
    2. `비지도 학습`
        - Y가 명시되지 않았거나 관심이 없고 `X의 패턴` 자체에 관심이 있는 문제
        - ex. 군집분석, 차원 축소
    3. `강화 학습`
        - 주어진 환경에서 최대의 보상을 달성하기 위한 정책의 학습
        - 임의 추출된 데이터가 아닌 전략적으로 선택된 데이터를 이용해 학습
        - ex. 바둑에서, 두는 수의 위치가 **x**이고 승리 혹은 패배가 **y**가 되며, 승리를 위해 어떤 수를 두어야 하는지를 학습 (for 목표 달성 - 승리)

- 절차 : `CRISP-DM 모델` (데이터 마이닝을 위한 일반적인 절차에 대한 표준)
    
    ![2024-10-22_15-57-51.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/40021a65-0369-439d-8a38-95358e5c5b40/2024-10-22_15-57-51.jpg)
    
    1. 문제 설정
        - 종속변수 Y 정의
    2. 데이터 수집
        - 관련 데이터 수집 (X, Y)
        - (기존 분석) 실험의 설계하고 수행하여 데이터 수집
        - (빅데이터 분석) 이미 존재하는 DB에서 관련된 모든 데이터를 수집
    3. 탐색적 데이터 분석 (EDA)
        - 데이터의 특성을 이해하고, 시각화 및 결측치 탐색과 같은 전처리 과정을 진행
    4. 모델링
        - 트레이닝 셋과 테스트 셋을 분리 (보통 시간순서에 따라)
        - 다양한 검증 과정을 통해 최종 모델을 선택한 후 성능을 평가
