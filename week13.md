# 1. 추천시스템 개요

- 추천시스템
    - 사용자의 과거 행동이나 다른 데이터를 바탕으로 사용자에게 필요한 정보, 제품을 제시해주는 시스템
        - 사용자 과거행동 : 구매, 평점, 리뷰, 관심 등
        - 다른 데이터 : 상품정보, 사용자 그룹 등
    - 개인화된 추천시스템 : 각 사용자 별로 맞춤형 추천을 제공
    - 인터넷 비즈니스의 발달과 함께 추천시스템도 같이 발달 - 개인화된 행동의 축적
    - 기본 원칙 : 사용자와 아이템 사이의 의존성
        - ex. 다큐멘터리를 많이 시청한 사용자는 액션 영화 보다는 다큐멘터리 영화에 관심이 있을 것

- 기본 모델
    1. 예측 모델 
        - 사용자-아이템 조합에 대한 평가값의 예측
        - m 사용자와 n 아이템의 경우 m x n 행렬에 대한 평가값 예측
        - 부분 데이터로부터 행렬을 완성하는 문제
    2. 랭킹모델
        - 사용자 별 상위 k개의 아이템을 추천 (top-k 추천 문제)
        - 아이템 별 관심을 가질 상위 k명의 사용자를 선별

- 추천 알고리즘의 분류
    
    ![2024-12-20_15-04-00.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/034df067-d0f5-4032-b31d-e37a1074b1bb/2024-12-20_15-04-00.jpg)
    

1. 컨텐츠 기반
    - 아이템의 설명 데이터(메타 데이터)를 추천에 활용
    - 비슷한 아이템을 추천
        - ex. 터미네이터를 본 사람에게 에얼리언을 추천
    - 아이템에 대한 다른 사용자의 평점 내역이 필요하지 않음 - 신규 아이템에 대한 추천이 가능
    - 추천하려는 사용자에 대한 사전 정보가 필요 - 신규 사용자의 추천에는 적합하지 않음
    - 추천의 다양성이 제한됨
    - 기존 아이템의 메타 데이터와 사용자 선호도가 주어졌을 때, 새로운 아이템에 대한 사용자 선호도를 예측하는 문제
        
        ![2024-12-20_15-07-18.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/7fe70dfc-0042-4e9e-b4e0-b1c1a200bee7/2024-12-20_15-07-18.jpg)
        
        1. 유사성 분석으로 아이템 선별
            - 중심점까지의 거리: A-싫어요 = 1.73, A-좋아요 = 1.00 → A는 추천
        2. 지도학습 모델을 이용한 예측
            - KNN (K=3) 모델: Pr[A = ‘좋아요‘] = 1, Pr[A = ‘싫어요’] = 0 → A는 추천

1. 협업 필터링
    - 다른 사용자의 행동을 참고하여 아이템을 추천
    - 유사한 사용자 그룹에서 공통적으로 관심을 갖는 아이템을 추천 → 대규모의 축적된 데이터가 필요
    - 장점 : 사용자가 기존에 관심을 두지 않았던 새로운 아이템에 대한 추천이 가능
    - 단점 : 데이터가 적은 경우나 신규 아이템/사용자에 대해서는 적용이 어려움
    
2. 지식 기반
    - 특정 분야 전문가의 도움을 받아 전체적을 지식구조를 만들고 이를 활용하여 추천
    - 자주 구매하지 않고 아이템별 스펙이 상이하며 사용자 리뷰가 거의 존재하지 않는 아이템의 추천에 유리
    - ex. 부동산, 자동차, 명품 등

1. 하이브리드 / 앙상블
    - 서로 다른 추천 방식을 복합적으로 사용하여 추천
    - 각 기술의 단점을 보완하여 좀 더 나은 성능을 추구
    - 일반적으로 가장 좋은 성능을 보이며, 실제 추천 시스템 구축에 필수적
    - ex. 새로운 상품에 대해서는 컨텐츠 기반 추천을 제공 & 사용자 리뷰가 축적되면 협업 필터링으로 전환

1. 딥러닝 추천
    - 컨텐츠 기반 추천에서 비정형 아이템 사이의 유사도 측정
    - 모델 기반 협업 필터링에서 기계학습 모델로 딥러닝 모델을 사용
    - 장점
        - 비선형적 관계에 대한 표현이 가능 (기존은 선형적 관계 위주)
        - 숨겨진 Feature에 대한 추출이 가능
        - 비정형 데이터 및 순열 데이터에 대한 복합적 사용이 가능
        - 다양한 플랫폼 및 다양한 신경망 구조의 활용이 가능

# 2. 협업 필터링 (CF)

- 가정 : 어떤 아이템에 대해서 비슷한 취향을 가진 사용자들은 다른 아이템에 대해서도 비슷한 취향을 가짐

- 추천 문제의 정의
    - m명의 사용자 & n개의 아이템
    - 사용자 $i$가 아이템 $j$에 대하여 제시한 평점 $r_{ij}$ 데이터 존재
    - 임의의 사용자 $k$와 아이템 $l$에 대하여 관측되지 않은 평점 $r_{kl}$ 을 예측하는 문제

## (1) 메모리 기반 CF

1. 사용자 기반 방식 : 타겟 사용자와 유사한 사용자들의 아이템 선호를 기반으로 추천
2. 아이템 기반 방식 : 타겟 아이템과 유사하게 선택 받은 아이템에 대하여 사용자를 추천

- ex. 사용자 기반 방식 - 사용자 U1에게 M4와 M5 중 추천할 아이템?
    
    ![2024-12-20_17-18-43.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/7f962f20-e821-426a-8fb3-874d998c41f4/2024-12-20_17-18-43.jpg)
    
    1. U1과 비슷한 취향의 사용자를 선별 → 상관분석을 통해 U3 & U4
    2. U3와 U4의 평점을 이용하여 M4와 M5의 평점을 예측 → 2 & 5
    3. M4와 M5 중에서 M5를 U1에게 추천

- 이슈
    1. 유사한 사용자 선별 과정에서 희소 행렬의 문제
        
          → 공통 평가 항목만 계산 or 빈 항목을 0이나 평균으로 보정
        
    2. 사용자 사이의 기본적인 차이점 보정 문제
        
          → 상관관계 기반의 거리 사용 (상관계수 or 코사인 유사도)
        
    3. 서로 다른 사용자의 평점 합계 계산 문제 
        
          → 가장 유사한 K명의 평균/중간값을 사용 or 유사도에 가중치를 두어 평균
        
    4. 사용자와 아이템이 증가할수록 계산량 증가 문제
        
          → 군집화 혹은 차원 축소와 함께 수행
        

## (2) 모델 기반 CF

- 사용자-아이템 평점을 표현하는 수학적 모델을 만들고, 그 모델을 데이터로부터 학습하는 방식
    - 장점: 데이터 희소성에 강함
    - 단점: 블랙박스 모델
        - 지도학습 모델은 결과는 알 수 있으나 내부 동작을 이해하기 어려움

- vs. 메모리 기반 협업 필터링
    - 용량 효율성 : 모델은 일반적으로 더 적은 공간 복잡도를 요구
    - 학습과 예측의 속도: 메모리 기반은 O(n2), 모델 기반은 일반적으로 O(n)의 계산량을 요구
    - 과적합 방지: 모델 기반은 규제화와 같은 다양한 기법을 사용할 수 있음

- vs. 일반적인 지도 학습
    - 독립 변수와 종속 변수의 명확한 구분이 없음
    - 훈련 데이터와 평가 데이터 사이의 명확한 구분이 없음 (정확한 성능 평가 어려움)
    - 변수와 표본이 명확히 구별되지 않음 (사용자 기반, 아이템 기반 모두 가능)
    - 문제가 유사하기 때문에 지도학습 기법을 적용하는 것이 가능 (앙상블, 규제화 등)
        
        ![2024-12-20_17-40-15.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/7b413a3b-988f-4b37-8129-ec19fb8ceed7/2024-12-20_17-40-15.jpg)
        

### 1) 지도학습 기반 모델

- 일반적인 지도 학습의 모델을 이용하여 관심 평점을 예측
    - 관측되지 않은 항목들에 대한 처리가 필요
        - EDA(탐색적 데이터 분석)을 통해 데이터 결측치 처리
        - 보통은 임의값으로 채우고 반복적 예측을 통해 처리
    
- 블랙박스 모델
    1. 초기값으로 관측되지 않은 항목을 평균, 단일값 등의 단순한 방법을 이용하여 채움
    2.  예측하려는 항목(Y) 이외의 항목을 독립변수(X)로 하여 Y를 예측하는 모델을 훈련
        - n개의 아이템에 대하여 서로 다른 n개의 모델을 사용하는 것도 가능
    3. 모델을 이용하여 관측되지 않은 항목을 모두 예측
    4. 예측된 값으로 채워진 데이터를 이용하여 수렴할 때까지 2~3 반복적용

- **나이브 베이지안 모델 (Naïve Bayesian Model) 활용**
    - $Pr[Y | X_1, X_2, …, X_p] \propto Pr[Y] Pr[X_1|Y] Pr[X_2|Y] … Pr[X_p|Y]$
    - ex. 이진 평점 행렬을 사용한 베이즈 방법
        
        ![2024-12-20_17-43-25.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/007ab184-4c99-4860-a98f-9b37b2545e08/2024-12-20_17-43-25.jpg)
        
        ![2024-12-20_17-43-42.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/b8e1e35f-e9f4-4dc6-844a-16900c2f58ad/2024-12-20_17-43-42.jpg)
        
        - 특정 소비자가 평가하지 않은 아이템에($r_{31}$) 대한 평점을 예측 (좋아요:1, 싫어요:-1)
        - 소비자 3이 아이템 2, 3, 4, 5일 때의 평점 활용 → $r_{31}$이 특정 평점일 조건부확률 계산
        - 나이브 베이지안 모델에 따라 모두 곱해 최종 평점 예측
        

### 2) 잠재변수(행렬분해) 기반 모델

- 잠재요인 모델을 이용하여 평점 행렬을 완성
    - 평점 행렬의 행과 열(사용자/아이템) 사이에는 높은 유사성이 존재 - 상호 의존성, 낮은 랭크 등
    - m x n 평점 행렬은 더 적은 수의 숨겨진 변수(잠재 변수)로 표현이 가능 → 차원 축소와 연관
    - 관측된 데이터로부터 잠재 변수를 찾아 관측되지 않은 평점을 재구성하여 평점 행렬을 완성

- 행렬 분해 (MF, Matrix Factorization)
    - m × n 행렬 R을 m × k 행렬 U와 n × k 행렬 V로 분해
    - k는 잠재 요인의 수 (튜닝 파라미터), 일반적으로 mn >> (관측된 평점의 수) > mk + nk 로 k를 설정
    - 관측된 평점에 제곱손실함수를 이용하여 행렬 분해가 가능
        
        ![2024-12-20_17-55-40.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/5d2757d7-c893-4499-a788-dea09e00830c/2024-12-20_17-55-40.jpg)
        
    1. 일반적 행렬 분해
        - 경사하강법 - 제곱손실 함수를 최소화 가능
        - 규제화 - 과대최적화 방지 가능
    2. 특이값 분해 (SVD)
        1. 완전 행렬의 경우
            - 한 행렬을 대각행렬(Σ)과 직교행렬(U,V)로 분해하는 기법
            - k < r로 줄인 행렬을 이용하여 원래 행렬을 근사(최소제곱에러)하는 것이 가능
                
                ![2024-12-21_00-21-05.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/26b614dd-71ee-487f-a947-85c75c097ff9/2024-12-21_00-21-05.jpg)
                
        2. 불완전 행렬의 경우
            - 직교한다는 제약조건 상에서 제곱손실함수를 최소화 (관측된 값만으로 최적화)
        - 더 간단한 방법
            1. 누락된 항목을 평균으로 치환하고 rank-k SVD를 수행
            2. 재구성된 값으로 누락된 항목을 치환하여 rank-k SVD를 수행 & 반복
            3. 초기값에 영향을 많이 받고, 수렴하지 않거나 local minimum에 도달할 수 있음
        - 특징
            - 각 잠재요인이 서로 직교하기 때문에 해석성이 높아질 수 있음
            - 사용자의 특성을 파악하기 쉬움
            - 많은 경우 제한없는 행렬 분해와 큰 차이가 없거나 성능은 떨어질 수 있음

- 비음행렬분해 (NMF, Non-negative Matrix Factorization)
    1. 완전 행렬의 경우
        - 원소가 음이 아닌 행렬을 두개의 음이 아닌 행렬로 분해
    2. 불완전 행렬의 경우
        1. 사전에 모든 원소값을 비음화 (같은 값을 더해서)
        2. 분해된 행렬이 음이 아니라는 조건 상에서 제곱손실을 최소화하여 분해
        3. 관측된 값만으로 최적화
    - 특징
        - 음의 선호도/가중치가 없기 때문에 해석이 쉬움
        - 0으로 예측되는 부분이 많아져 자연스럽게 군집화가 이루어짐
        - 일반적으로 제곱에러로 측정되는 성능은 높지 않음

# 3. 딥러닝 추천

- 컨텐츠 기반 추천
    - 텍스트, 음악, 그림 등의 비정형 데이터에서 피처를 추출하여 유사한 컨텐츠를 추천하는데 사용
- 협업 필터링 추천
    - MLP: 주로 MF를 개선하는 목적으로 사용 (NeuralCF, DeepFM, Wide&Deep Learning)
    - Autoencoder: 차원 축소와 재구성을 딥러닝을 통해 수행 (RBM-Rec, AutoRec, CDAE)
    - RNN/CNN 기반: 순차추천에 사용 (GRU4Rec, Caser, SLi-Rec)
    - Transformer 기반: Transformer를 차용 (SASRec, SSE-PT, BERT4Rec)

### (1) NeuralCF

- **NeuralCF**
    - 선형 기반의 MF를 비선형 모델인 DNN을 이용하여 확장
    - Sparse한 사용자/아이템 프로파일을 dense하게 embedding
    - 선형결합 대신 NN을 이용하여 평점을 예측

- 학습 방법
    - 평점 형식의 피드백: 제곱손실의 사용, 암시적 부정 샘플을 사용하지 않음
    - 긍정 형식의 피드백: 크로스 엔트로피 로스의 사용, 암시적 부정 샘플을 사용

- 암시적 부정 샘플 (implicit negative sample)
    - 관측되지 않은 데이터는 사용자가 부정적으로 평가하는 아이템일 확률이 높음
        - 많은 아이템 중에 사용자는 보통 소수의 아이템에만 관심 있음
        - 관심있는 아이템은 관측되었을 확률이 높음

### (2) AutoRec

- Autoencoder: 비선형적 차원 축소 및 복원 딥러닝 모델
    - 고차원 데이터를 저차원의 잠재변수로 표현(인코드) 및 복원(디코드)
- 잠재변수 기반 추천: 고차원 평점 행렬을 저차원 행렬로 분해 후 복원

- **AutoRec**
    - 고차원 사용자 프로파일을 저차원 잠재변수로 표현 및 복원
    - 예측하려는 평점을 0으로 세팅 후 표현과 복원을 하여 예측
    - 훈련 시 관측된 데이터에 대해서면 경사도를 업데이트

### (3) GRU4Rec & BERT4Rec

- 일반적 추천 (Conventional Recommendation)
    - 과거 사용자-아이템 피드백을 기반으로 새로운 아이템 추천
    - 피드백이 발생한 시간 혹은 발생 순서를 고려하지 않음
    - ex. 1년 전 본 영화와 지난주 본 영화가 같이 고려됨
    
- ****순차적 추천 **(Sequential Recommendation)**
    - 웹시스템이 발전하면서 사용자 행동을 시간 순으로 관리하는 것이 가능
    - 사용자의 과거 행동에 기반하여 다음 번 아이템을 추천하는 문제

- 언어 모델과 순차적 추천은 근본적으로 유사
    - 각 단어/아이템은 One-hot 인코딩으로 표현
    - 앞선 정보를 바탕으로 다음 단어/아이템을 예측
    
- GRU4Rec
    - GRU를 이용히여 순차적 추천시스템 구현

- BERT4Rec
    - 언어 모델에서 가장 성공적인 BERT를 가져와 추천에 적용
    - 단방향이 아닌 양방향 Self-Attention을 사용
        - 사용자 행동의 순서가 절대적이지 않음 & 훈련 과정에서 꼭 순서를 지킬 필요는 없음
    - 모델 훈련을 위해 Masking 기반의 Self-Supervised 학습을 이용
        - 기존에는 과거 히스토리를 기반으로 다음의 것을 예측하는 방식으로 학습
        - 일정 비율로 아이템들이 랜덤하게 mask하고, 이 부분을 학습
        - 훨씬 더 많은 샘플을 학습하는 것이 가능
        - 테스트할때는 시퀀스의 마지막에 [mask]를 넣어 해당하는 아이템을 예측
